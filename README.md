# Autonomous Drone Inspection of NIST Buckets
Autonomous search, inspection and detection of National Institute of Standards and Technology (NIST) buckets indoors using voxl m500 drone.

![BUCKET ALIGNMENT](https://link-to-your-bucket-alignment-image.png)

*Figure 1: Illustration of the GROUND bucket alignment.*

## Overview
This project employs a drone to autonomously inspect buckets in an unknown environment. The buckets are organized in various alignments, each represented by a unique AprilTag. The drone searches a predefined area of interest and upon detecting an AprilTag, it loads the inspection routine corresponding to that tag's bucket alignment. During inspection, the drone utilizes a custom YOLOv5 model for detecting what's inside the buckets.

## Introduction
This project's goal was to create software that uses a drone's onboard camera to localize a bucket configuration representing indoor debris in a disaster scenario, aiming to automate the task of a human pilot navigating around these obstacles. By using AprilTag, we simplified the complex task of debris detection into detecting and localizing an AprilTag on the bucket configuration. The drone was then instructed to move to certain predefined poses where its tracking camera could look into the buckets.

A JSON file containing these poses was generated by a program, "generate_waypoints", for each bucket configuration. The localization of the bucket configuration in the local inertial frame was performed using the Pose of the AprilTag in the drone's camera frame and the drone's own pose estimate in the local inertial frame.

By chaining several homogeneous transformations, we obtained the desired pose of the drone in the local inertial frame and fed this information into the drone's autopilot. Smooth drone movement was achieved by controlling yaw rates rather than absolute yaw angles, which reduced image blur from the tracking camera.

This project is primarily built around the ROS (Robot Operating System) framework, and uses MAVROS for interfacing with the PX4 autopilot. The inspection routines are defined as a series of waypoints and movements around the bucket alignments.

## Getting Started

To run the project, clone the repository, navigate to the root of the workspace and build the packages using `catkin_make`. Then, source the workspace's setup file and launch the project using the launch file. 

## Project Structure

The project is organized in the following directories:

- `src`: Contains the main ROS node (`NFRA_node`) for controlling the drone, and utilities for various tasks like waypoint management, reading bucket configurations, etc.
- `include`: Contains header files for the utilities.
- `launch`: Contains ROS launch files for starting the project.

The `NFRA_node` is the central component of the project, and coordinates the bucket inspection process. It uses MAVROS services and publishes to MAVROS topics to command the drone.

## Significant files
Two main files, "project.cpp" and "utils.cpp", along with a few supporting files and libraries, are responsible for most of the project's implementation. The "project.cpp" file is the main file, whereas "utils.cpp" contains utility functions.

### project.cpp
This file contains the main logic of the software, starting with initializing ROS node, Subscribers, and Publishers. It then reads JSON files containing the waypoint offsets for each bucket. When the drone spots an AprilTag, it loads the corresponding JSON file based on the AprilTag's ID and begins navigating to each waypoint.

For each waypoint, the drone calculates its desired pose in the local inertial frame, which is subsequently published to the "/mavros/setpoint_raw/local" rostopic. The drone continues towards its goal until it approximately reaches the desired position and yaw angle, which is determined using the "drone_is_approximately_at_offset" function from the "utils.cpp" file.

This file also handles the logic for when to transition from one bucket to the next. The desired tolerances are defined as global variables at the top of the "project.cpp" file and can be easily modified to suit the mission requirements.

### utils.cpp
This file contains several utility functions that assist the main program. The "determine_yaw_rate" function calculates the difference in yaw angle between the drone's current pose and its desired pose. This allows us to control the drone's yaw rate for smoother navigation and better image quality.

The "drone_is_approximately_at_offset" function checks if the drone's configuration, defined by its yaw angle and position, is within some predefined tolerance of the desired drone configuration. This helps to determine whether the drone has reached its destination (bucket location) or not.

## Bucket Configurations

Each bucket alignment is represented by a unique AprilTag. The bucket configurations are stored in JSON files inside the `config` directory, and handled by the `BucketConfiguration` class. Each configuration specifies the name of the bucket alignment and an offset matrix.

For example, the "GROUND" bucket alignment is represented by the following configuration:

```json
{
    "name": "GROUND",
    "offset": [ /* offset matrix */ ]
}
```

## Mathematical Description

![TRANSFORMATION FRAMES](https://link-to-your-transformation-frames-image.png)

*Figure 2: Illustration of the different reference frames.*

To ensure the drone can navigate accurately around the buckets, the desired pose of the drone is calculated with respect to the AprilTag's frame (which is obtained from the AprilTag detection library). This pose is transformed to the drone's body frame using the equation:

```
pose_body = pose_tag_inverse * pose_desired_tag
```

Finally, the pose in the body frame is transformed to the inertial frame (earth-fixed frame) by multiplying it with the drone's current pose in the inertial frame:

```
pose_inertial = pose_body * pose_current_inertial
```

The pose in the inertial frame is then published and used by the PX4 autopilot for navigation.

## Demonstration Video

![DEMO VIDEO](https://link-to-your-demo-video.png)

*Figure 3: Demonstration video of the autonomous inspection of the "GROUND" bucket alignment by the drone.*

## TODO

- Implement a search routine for the drone to navigate a predefined area of interest.
- Allow the drone to switch between the search and inspection routines dynamically.
- Implement the custom YOLOv5 model for detecting objects within the buckets during the inspection routine.

## Acknowledgments

A big thank you to [Zach Bortoff](https://github.com/zborffs) for his significant contributions to the initial phase of this project.

## References

- [AprilTag 3](https://github.com/AprilRobotics/ap

riltag)
- [PX4 Autopilot](https://github.com/PX4/PX4-Autopilot)
- [MAVROS](https://github.com/mavlink/mavros)
- [Custom YOLOv5 Model](https://github.com/<your-github>/<your-repo>)

